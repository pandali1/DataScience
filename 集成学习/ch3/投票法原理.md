# 投票法的原理

<img src="https://gitee.com/panli1998/mycloudimage/raw/master/img/image-20210413143353641.png" alt="image-20210413143353641" style="zoom:50%;" />

如上图所示，在同一训练集上，训练得到多个分类或回归模型，然后通过一个投票器，通过某种加权方式，输出得票率最高的结果。

## 集成模型好于单个分类器的原因

假设：n个基分类器的出错率都是$\epsilon$，且相互独立，则n个基分类器的结果中，出现k个错误的数量服从二项分布，对集成模型（简单多数投票）来说，n个结果中，有K个错误的概率是：

<img src="https://gitee.com/panli1998/mycloudimage/raw/master/img/image-20210413144209168.png" alt="image-20210413144209168" style="zoom:33%;" />

当K>n/2时，集成模型输出错误结果

假设$\epsilon=0.25,n=11$，输出错误结果的概率为：

<img src="https://gitee.com/panli1998/mycloudimage/raw/master/img/image-20210413144430613.png" alt="image-20210413144430613" style="zoom:33%;" />



如图片所示，只有当基分类器的错误率$\epsilon<0.5$时，多数投票的继承分类器出错率才会低于单个分类器

## 加权多数投票

### 硬投票

不同的基模型可能有不同的正确率，因此需要赋予不同的结果权重值

<img src="https://gitee.com/panli1998/mycloudimage/raw/master/img/image-20210413150821176.png" alt="image-20210413150821176" style="zoom:33%;" />

$w_j表示分类器C_j对应的权重，\hat y是输出类标，\chi_A是类标为i的一个分类器集合$

### 软投票

<img src="https://gitee.com/panli1998/mycloudimage/raw/master/img/image-20210413151306317.png" alt="image-20210413151306317" style="zoom:45%;" />

$p_{ij}是第j个分类器预测为i的概率$

## 投票法的使用条件

- **基模型之间的效果不能差别过大**。当某个基模型相对于其他基模型效果过差时，该模型很可能成为噪声。
- **基模型之间应该有较小的同质性。**例如在基模型预测效果近似的情况下，基于树模型与线性模型的投票，往往优于两个树模型或两个线性模型。

# 投票法案例